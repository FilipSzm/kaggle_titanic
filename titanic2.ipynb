{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets\\\\titanic\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7648/4291678729.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_titanic_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_titanic_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7648/4291678729.py\u001b[0m in \u001b[0;36mload_titanic_data\u001b[1;34m(filename, titanic_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_titanic_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitanic_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTITANIC_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcsv_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitanic_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_titanic_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\FPro\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets\\\\titanic\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "iterat = 7\n",
    "\n",
    "for i in range(1000000):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import metrics\n",
    "\n",
    "\n",
    "    import os\n",
    "    TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "        csv_path = os.path.join(titanic_path, filename)\n",
    "        return pd.read_csv(csv_path)\n",
    "\n",
    "    train_data = load_titanic_data(\"train.csv\")\n",
    "    test_data = load_titanic_data(\"test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    y_train = train_data['Survived'].values\n",
    "    X_train = train_data.drop('Survived', axis=1)\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "    # A class to select numerical or categorical columns \n",
    "    # since Scikit-Learn doesn't handle DataFrames yet\n",
    "    class CustomDataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "        repl_name = {\n",
    "            'Rev': 0,\n",
    "            'Sir': 0,\n",
    "            'Don': 0,\n",
    "            'Lady': 0,\n",
    "            'Jonkheer': 0,\n",
    "            'the Countess': 0,\n",
    "            'Ms': 0,\n",
    "            'Capt': 0,\n",
    "            'Mme': 0,\n",
    "            'Mlle': 0,\n",
    "            'Mr': 1,\n",
    "            'Mrs': 2,\n",
    "            'Miss': 3,\n",
    "            'Master': 4,\n",
    "            'Dr': 4,\n",
    "            'Col': 5,\n",
    "            'Major': 5\n",
    "        }\n",
    "\n",
    "        repl_parch = {\n",
    "            6: 0,\n",
    "            4: 0,\n",
    "            5: 1,\n",
    "            0: 2,\n",
    "            3: 3,\n",
    "            1: 4,\n",
    "            2: 5\n",
    "        }\n",
    "\n",
    "        repl_embark = {\n",
    "            'S': 0,\n",
    "            'Q': 1,\n",
    "            'C': 2\n",
    "        }\n",
    "\n",
    "        repl_sib = {\n",
    "            8: 0,\n",
    "            5: 0,\n",
    "            4: 1,\n",
    "            3: 2,\n",
    "            0: 3,\n",
    "            2: 4,\n",
    "            1: 4\n",
    "        }\n",
    "\n",
    "        repl_cab = {\n",
    "            'T': 0,\n",
    "            'D': 1,\n",
    "            'E': 1,\n",
    "            'B': 1,\n",
    "            'U': 2,\n",
    "            'F': 3,\n",
    "            'C': 4,\n",
    "            'A': 5,\n",
    "            'G': 6\n",
    "        }\n",
    "\n",
    "        repl_sex = {\n",
    "            'male': 1,\n",
    "            'famale': 0\n",
    "        }\n",
    "\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "        def transform(self, X):\n",
    "            X['Name'] = X['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "            titles = X['Name'].unique()\n",
    "\n",
    "            X['Age'].fillna(-1, inplace=True)\n",
    "            medians = dict()\n",
    "            for title in titles:\n",
    "                median = X.Age[(X[\"Age\"] != -1) & (X['Name'] == title)].median()\n",
    "                medians[title] = median\n",
    "\n",
    "            for index, row in X.iterrows():\n",
    "                if row['Age'] == -1:\n",
    "                    X.loc[index, 'Age'] = medians[row['Name']]\n",
    "\n",
    "            X['Fare'].fillna(-1, inplace=True)\n",
    "            medians = dict()\n",
    "            for pclass in X['Pclass'].unique():\n",
    "                median = X.Fare[(X[\"Fare\"] != -1) & (X['Pclass'] == pclass)].median()\n",
    "                medians[pclass] = median\n",
    "\n",
    "            for index, row in X.iterrows():\n",
    "                if row['Fare'] == -1:\n",
    "                    X.loc[index, 'Fare'] = medians[row['Pclass']]\n",
    "\n",
    "            X['Name'] = X['Name'].apply(lambda x: self.repl_name.get(x))\n",
    "            X['Parch'] = X['Parch'].apply(lambda x: self.repl_parch.get(x))\n",
    "            X['Embarked'] = X['Embarked'].apply(lambda x: self.repl_embark.get(x))\n",
    "            X['SibSp'] = X['SibSp'].apply(lambda x: self.repl_sib.get(x))\n",
    "            X['Sex'] = X['Sex'].apply(lambda x: self.repl_sex.get(x))\n",
    "\n",
    "            X['Cabin'].fillna('U', inplace=True)\n",
    "            X['Cabin'] = X['Cabin'].apply(lambda x: x[0])\n",
    "            X['Cabin'] = X['Cabin'].apply(lambda x: self.repl_cab.get(x))\n",
    "\n",
    "\n",
    "            return X[['Age', 'Name', 'Fare', 'Pclass', 'Parch', 'Embarked', 'SibSp', 'Cabin', 'Sex']]\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    seed=34235237\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "\n",
    "\n",
    "    X_copy = X_train\n",
    "    y_copy = y_train\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "    from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "    # classifier = XGBClassifier()\n",
    "    # X_copy = X_train\n",
    "\n",
    "    # for i in range(1000):\n",
    "        \n",
    "\n",
    "    X_train = X_copy\n",
    "    y_train = y_copy\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # param_grid = {\n",
    "    #             'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    # }\n",
    "\n",
    "    # grid = GridSearchCV(pipe, param_grid, cv=kfold)\n",
    "\n",
    "    # grid.fit(X_train, y_train)\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            (\"select_numeric\", CustomDataFrameSelector()),\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "            # (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
    "        ])\n",
    "\n",
    "\n",
    "    classifier = RandomForestClassifier(bootstrap=False,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('preprocessing', num_pipeline), \n",
    "            ('classifier', classifier)])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    score = pipe.score(X_test, y_test)\n",
    "    # print(score)\n",
    "     \n",
    "    if score > 0.87082:\n",
    "        submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": pipe.predict(test_data)\n",
    "        })\n",
    "\n",
    "        submission.to_csv(\"submission\" + iterat + \".csv\", index=False)\n",
    "        iterat+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # num_pipeline.fit_transform(X_train)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0856325a1a198aa25f0fd5bb76f348f8c400869d5b5d3ab07430f9b6560af064"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
